{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.animation import ArtistAnimation, FFMpegWriter\n",
    "\n",
    "path_bousinessq = \"./boussinesq.nc\"\n",
    "path_2dcylinder = \"./cylinder2d.nc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataset(path):\n",
    "    return Dataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cylinder2D = loadDataset(path_2dcylinder)\n",
    "boussinesq = loadDataset(path_bousinessq)\n",
    "print(cylinder2D)\n",
    "print(boussinesq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info about the datasets\n",
    "\n",
    "### Cylinder 2D\n",
    "\n",
    "    dimensions(sizes): xdim(640), ydim(80), tdim(1501), const(1)\n",
    "\n",
    "    variables(dimensions): float32 u(tdim,ydim,xdim), float32 v(tdim,ydim,xdim), float32 xdim(xdim), float32 ydim(ydim), float32 tdim(tdim), float32 nu(const),                             float32 radius(const), float32 Re(const)\n",
    "\n",
    "### Bousinessq\n",
    "\n",
    "\n",
    "    dimensions(sizes): xdim(150), ydim(450), tdim(2001), const(1)\n",
    "\n",
    "    variables(dimensions): float32 u(tdim,ydim,xdim), float32 v(tdim,ydim,xdim), float32 xdim(xdim), float32 ydim(ydim), float32 tdim(tdim),\n",
    "                           float32 radius(const), float32 obstacle_pos_x(const), float32 obstacle_pos_y(const)\n",
    "\n",
    "### Accessing variables\n",
    "\n",
    "    cylinder2D['variable_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(cylinder2D['xdim'])\n",
    "print(cylinder2D['u'].shape)\n",
    "print(cylinder2D['tdim'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = cylinder2D\n",
    "\n",
    "def velFromUV(data):\n",
    "    \n",
    "    u = data['u'][1000,:,:]\n",
    "    v = data['v'][1000,:,:]\n",
    "\n",
    "    vel = np.sqrt(u**2 + v**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u = np.array(cylinder2D['u'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ims = [[ax.imshow(u[i], animated=True)] for i in range(1, len(u))]\n",
    "\n",
    "ani = ArtistAnimation(fig, ims, interval=1000 , blit=True, repeat_delay=1000)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# writer = FFMpegWriter(fps=15, metadata=dict(artist='Me'), bitrate=1800)\n",
    "# ani.save(\"movie.mp4\", writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(data['v'][1000,:,:])\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "% Create snapshot matrix\n",
    "Nt = length(S(1,1,:));\n",
    "S = reshape(permute(S, [3 2 1]), Nt, [ ]); % Reshape data into a matrix S with Nt rows\n",
    "U = S - repmat(mean(S,1), Nt, 1); % Subtract the temporal mean from each row\n",
    "\n",
    "% Create correlation matrix\n",
    "C_s = (U*U')/(Nt-1);\n",
    "\n",
    "% Solve eigenvalue problem\n",
    "[A_s LAM_s] = eig(C_s,'vector');\n",
    "\n",
    "% Sort eigenvalues and eigenvectors\n",
    "[lambda_s,ilam_s] = sort(LAM_s,'descend');\n",
    "A_s = A_s(:, ilam_s);\n",
    "\n",
    "% These are the temporal modes\n",
    "% Calculate spatial coefficients\n",
    "PHI_s = U'*A_s;\n",
    "\n",
    "% Reconstruction on mode k\n",
    "k = 1; % for example\n",
    "Utilde_k_s = A_s(:,k)*PHI_s(:,k)';\n",
    "\n",
    "% Normalization to match direct and snapshot modes (optional)\n",
    "PHI = normc(PHI_s);\n",
    "\n",
    "% Spatial modes\n",
    "A = U*PHI;\n",
    "\n",
    "% Time coefficients\n",
    "Utilde_k = A(:,k)*PHI(:,k)';\n",
    "% Reconstruction on mode k\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S = np.transpose(u, (1,2,0))\n",
    "print(S.shape)\n",
    "Nt = u.shape[0]\n",
    "print(Nt)\n",
    "U = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "url = \"https://cgl.ethz.ch/Downloads/Data/ScientificData/cylinder2d_nc.zip\"\n",
    "file_name = \"../data2/\" + url.split('/')[-1]\n",
    "with ZipFile(file_name, 'r') as zipObj:\n",
    "   zipObj.extractall('temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input=np.load('../data/cylinder_u.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output=np.load('../output/80.npy')\n",
    "ip=np.load('../input/80.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Output[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ip[500])\n",
    "# plt.imshow(ip[510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(Input[500])\n",
    "plt.imshow(Input[510])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(1)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(Output[800])\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(Input[800])\n",
    "plt.savefig('comp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Output[800]-ip[800])\n",
    "plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(Output[200][:,100]-Input[200][:,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(Input[800]))\n",
    "print(np.min(Output[800]))\n",
    "print(np.max(Input[800]))\n",
    "print(np.max(Output[800]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(ip[800]))\n",
    "print(np.max(ip[800]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import torchvision\n",
    "from model import MyDataset, MLP_Dataset, LSTM_Dataset, autoencoder, MLP, Unet, LSTM\n",
    "from train import training,validation\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LSTM(\n  (lstm1): LSTM(10, 64, num_layers=3, batch_first=True)\n  (lstm2): LSTM(64, 10, num_layers=3, batch_first=True)\n  (encoder): Sequential(\n    (0): Conv2d(1, 16, kernel_size=(3, 4), stride=(1, 8), padding=(1, 1))\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): LeakyReLU(negative_slope=0.01)\n    (12): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (14): LeakyReLU(negative_slope=0.01)\n  )\n  (decoder): Sequential(\n    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.01)\n    (3): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): LeakyReLU(negative_slope=0.01)\n    (9): ConvTranspose2d(32, 16, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (11): LeakyReLU(negative_slope=0.01)\n    (12): ConvTranspose2d(16, 1, kernel_size=(3, 8), stride=(1, 8), padding=(1, 0))\n    (13): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (down): Linear(in_features=6400, out_features=10, bias=True)\n  (up): Linear(in_features=10, out_features=6400, bias=True)\n)\nencoder.0.weight\nencoder.0.bias\nencoder.1.weight\nencoder.1.bias\nencoder.3.weight\nencoder.3.bias\nencoder.4.weight\nencoder.4.bias\nencoder.6.weight\nencoder.6.bias\nencoder.7.weight\nencoder.7.bias\nencoder.9.weight\nencoder.9.bias\nencoder.10.weight\nencoder.10.bias\nencoder.12.weight\nencoder.12.bias\nencoder.13.weight\nencoder.13.bias\ndecoder.0.weight\ndecoder.0.bias\ndecoder.1.weight\ndecoder.1.bias\ndecoder.3.weight\ndecoder.3.bias\ndecoder.4.weight\ndecoder.4.bias\ndecoder.6.weight\ndecoder.6.bias\ndecoder.7.weight\ndecoder.7.bias\ndecoder.9.weight\ndecoder.9.bias\ndecoder.10.weight\ndecoder.10.bias\ndecoder.12.weight\ndecoder.12.bias\ndecoder.13.weight\ndecoder.13.bias\ndown.weight\ndown.bias\nup.weight\nup.bias\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nTrue\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\nFalse\n"
     ]
    }
   ],
   "source": [
    "pretrained = autoencoder()\n",
    "# print(pretrained.encoder[0].weight)\n",
    "# print(pretrained)\n",
    "model = LSTM()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "PATH = \"../weights/1000.pth\"\n",
    "checkpoint = torch.load(PATH)\n",
    "# print(checkpoint.keys())\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "# optimizer.load_state_dict\n",
    "\n",
    "print(model)\n",
    "\n",
    "count = 0\n",
    "\n",
    "layers = []\n",
    "\n",
    "for param in pretrained.named_parameters():\n",
    "    print(param[0])\n",
    "    layers.append(param[0])\n",
    "\n",
    "for param in model.named_parameters():\n",
    "    if param[0] in layers:\n",
    "        param[1].requires_grad = False\n",
    "    count += 1\n",
    "\n",
    "# print(model.lstm2.weight_ih_l2)\n",
    "# print(count)\n",
    "for param in model.named_parameters():\n",
    "    print(param[1].requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load transfer_learning(pretrained, model, PATH):\n",
    "\n",
    "    PATH = \"../weights/1000.pth\"\n",
    "    checkpoint = torch.load(PATH)\n",
    "    model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "    layers = []\n",
    "\n",
    "    for param in pretrained.named_parameters():\n",
    "        layers.append(param[0])\n",
    "\n",
    "    for param in model.named_parameters():\n",
    "        if param[0] in layers:\n",
    "            param[1].requires_grad = False\n",
    "\n",
    "    for param in model.named_parameters():\n",
    "        print(param[1].requires_grad)\n",
    "\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}